{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM(Long Short Term Memory) 가격 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시계열(time-series) 데이터에 적용하기에 알맞는 RNN(Recurrent Neural Network)의 한 종류인 LSTM(Long Short Term Memory) 모델을 사용하여 자산의 가격을 예측합니다.\n",
    "\n",
    "딥러닝 모델인 LSTM을 활용하기 때문에 기존에 사용했었던 파이썬 라이브러리들에 추가로 tensorflow라는 딥러닝 라이브러리와 keras라는 tensorflow의 래핑 라이브러리를 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.tsa.seasonal as smt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import random # 무작위 숫자를 생성하는 라이브러리\n",
    "import datetime as dt\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "#import plotly\n",
    "\n",
    "# tensorflow의 래핑 라이브러리인 keras에서 본 튜토리얼에 사용할 기능들\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv file path 설정\n",
    "ktb_path = \"./csv/ktb.csv\"\n",
    "lktb_path = \"./csv/lktb.csv\"\n",
    "k200_path = \"./csv/k200.csv\"\n",
    "usdkrw_path = \"./csv/usdkrw.csv\"\n",
    "\n",
    "# csv파일을 dataframe형태로 가져오기\n",
    "#df = pd.read_csv(k200_path, index_col=0, parse_dates=['date'])\n",
    "df = pd.read_csv(k200_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력받은 데이터를 학습 데이터와 시험 데이터로 나누는 과정입니다.\n",
    "\n",
    "특정 시각을 선택하고 그 시각 이전의 데이터는 학습 데이터로, 그 시각 이후의 데이터는 시험 데이터로 활용하는 방법으로 학습 데이터와 시험 데이터를 분리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 10\n",
    "\n",
    "# 학습 데이터와 시험 데이터를 나누는 기준일 설정\n",
    "split_date = list(df[\"date\"][-(2*window_len+1):])[0]\n",
    "\n",
    "# 앞에서 설정된 기준일을 기점으로 학습 데이터와 시험 데이터 분리\n",
    "training_set, test_set = df[df['date'] < split_date], df[df['date'] >= split_date]\n",
    "training_set = training_set.drop(['date','dividend', 'split'], 1)\n",
    "test_set = test_set.drop(['date','dividend','split'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_set[:3])\n",
    "\n",
    "print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 윈도우 생성\n",
    "LSTM_training_inputs = []\n",
    "for i in range(len(training_set)-window_len):\n",
    "    temp_set = training_set[i:(i+window_len)].copy()\n",
    "    \n",
    "    for col in list(temp_set):\n",
    "        temp_set[col] = temp_set[col]/temp_set[col].iloc[0] - 1\n",
    "    \n",
    "    LSTM_training_inputs.append(temp_set)\n",
    "LSTM_training_outputs = (training_set['close'][window_len:].values/training_set['close'][:-window_len].values)-1\n",
    "\n",
    "LSTM_training_inputs = [np.array(LSTM_training_input) for LSTM_training_input in LSTM_training_inputs]\n",
    "LSTM_training_inputs = np.array(LSTM_training_inputs)\n",
    "\n",
    "# 시험 데이터 윈도우 생성\n",
    "LSTM_test_inputs = []\n",
    "for i in range(len(test_set)-window_len):\n",
    "    temp_set = test_set[i:(i+window_len)].copy()\n",
    "    \n",
    "    for col in list(temp_set):\n",
    "        temp_set[col] = temp_set[col]/temp_set[col].iloc[0] - 1\n",
    "    \n",
    "    LSTM_test_inputs.append(temp_set)\n",
    "LSTM_test_outputs = (test_set['close'][window_len:].values/test_set['close'][:-window_len].values)-1\n",
    "\n",
    "LSTM_test_inputs = [np.array(LSTM_test_inputs) for LSTM_test_inputs in LSTM_test_inputs]\n",
    "LSTM_test_inputs = np.array(LSTM_test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['close'][window_len:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['close'][:-window_len].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_training_inputs\n",
    "#LSTM_test_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_training_inputs_one = []\n",
    "\n",
    "for i in range(0, len(LSTM_training_inputs)):\n",
    "    LSTM_training_inputs_one.append(LSTM_training_inputs[i][:,3])\n",
    "\n",
    "LSTM_test_inputs_one = []\n",
    "\n",
    "for i in range(0, len(LSTM_test_inputs)):\n",
    "  \n",
    "  LSTM_test_inputs_one.append(LSTM_test_inputs[i][:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(LSTM_training_inputs_one, LSTM_training_outputs)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "predictions = lin_reg.predict(LSTM_test_inputs_one)\n",
    "MAE = mean_absolute_error(LSTM_test_outputs, predictions)\n",
    "print(MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(LSTM_test_outputs, label = \"actual\")\n",
    "plt.plot(predictions, label = \"predicted\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "MAE = mean_absolute_error(LSTM_test_outputs, predictions)\n",
    "print('The Mean Absolute Error is : {}'.format(MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=50)\n",
    "forest_reg.fit(LSTM_training_inputs_one, LSTM_training_outputs)\n",
    "\n",
    "predictions = forest_reg.predict(LSTM_test_inputs_one)\n",
    "forest_mae = mean_absolute_error(LSTM_test_outputs, predictions)\n",
    "forest_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(LSTM_test_outputs, label = \"actual\")\n",
    "plt.plot(predictions, label = \"predicted\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "MAE = mean_absolute_error(LSTM_test_outputs, predictions)\n",
    "print('The Mean Absolute Error is : {}'.format(MAE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LSTM 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(inputs, output_size, neurons, activ_func=\"linear\",\n",
    "                dropout=0.10, loss=\"mae\", optimizer=\"adam\"):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, input_shape=(inputs.shape[1], inputs.shape[2])))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(units=output_size))\n",
    "    model.add(Activation(activ_func))\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LSTM 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 LSTM 모델을 학습하는 단계입니다.\n",
    "\n",
    "코드 실행 후 매 Epoch 마다 모델의 loss가 줄어드는 것이 확인되면 모델이 데이터를 성공적으로 학습하고 있는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = build_model(LSTM_training_inputs, output_size=1, neurons = 32)\n",
    "\n",
    "\n",
    "\n",
    "nn_history = nn_model.fit(LSTM_training_inputs, LSTM_training_outputs, \n",
    "                            epochs=5, batch_size=1, verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. LSTM 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만들어진 모델을 평가합니다.\n",
    "\n",
    "평가 기준은 MAE(Mean Absolute Error)로 매 회 오차 절대값들의 평균입니다.\n",
    "\n",
    "우선 10개의 데이터를 사용해서 바로 다음 1단계를 예측하는 성능을 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(LSTM_test_outputs, label = \"actual\")\n",
    "plt.plot(nn_model.predict(LSTM_test_inputs), label = \"predicted\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "MAE = mean_absolute_error(LSTM_test_outputs, nn_model.predict(LSTM_test_inputs))\n",
    "print('The Mean Absolute Error is: {}'.format(MAE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 같은 모델을 사용해서 10단계 앞의 주가를 얼마나 정확하게 예측 가능한지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence_full(model, data, window_size):\n",
    "    curr_frame = data[0]\n",
    "    predicted = []\n",
    "    for i in range(len(data)):\n",
    "        predicted.append(model.predict(curr_frame[np.newaxis,:,:])[0,0])\n",
    "        curr_frame = curr_frame[1:]\n",
    "        curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)\n",
    "    return predicted\n",
    "\n",
    "predictions = predict_sequence_full(nn_model, LSTM_test_inputs, 10)\n",
    "\n",
    "plt.plot(LSTM_test_outputs, label=\"actual\")\n",
    "plt.plot(predictions, label=\"predicted\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "MAE = mean_absolute_error(LSTM_test_outputs, predictions)\n",
    "print('The Mean Absolute Error is: {}'.format(MAE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오차가 상당히 크게 발생하는 것을 알 수 있습니다.\n",
    "\n",
    "LSTM 모델의 옵션들과 학습 Epoch 수 등을 변화시켜가며 성능이 어떻게 달라지는지 확인해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
